---
title: "Reproducibility Report for Poli et al. (2024, Developmental Science)"
author: "Victoria Hennessy (vhennessy@ucsd.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Reproducibility reports should all use this template to standardize reporting across projects. These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

*\[No abstract is needed.\] Each reproducibility project will have a straightforward, no frills report of the study and reproducibility results. These reports will be publicly available as supplementary material for the aggregate report(s) of the project as a whole. Also, to maximize project integrity, the intro and methods will be written and critiqued in advance of your attempt to reproduce the results. Introductions can be just 1-2 paragraphs clarifying the main idea of the original study, the target finding for your reproducibility attempt, and any other essential information. It will NOT have a literature review -- that is in the original publication. You can write both the introduction and the methods in past tense.*

**Clarify key analysis of interest here: Hierarchical Bayesian Modeling**

### Justification for choice of study

My current line of research focuses on individual differences in early information seeking. To study infant learning strategies, Poli and colleagues (2020; 2024) have developed an analytic pipeline that leverages an infant-friendly visual learning (VL) task from which information-theoretic measures (e.g., **predictability and information gain**) can be derived for each trial in sequences of visual events.

These measures are then incorporated into a hierarchical Bayesian model fitted to real infants' looking behavior (look-aways, looking time, and saccadic latency) in the VL task to infer the values of latent parameters that represent specific cognitive functions: **processing speed**, **learning performance**, **curiosity**, and **sustained attention** (see Figure 1).

[![Figure 1. The research pipeline in Poli et al. 2024 (Figure 2 in the original paper). The current project will focus on the first three boxes outlined in yellow: (1) reproducing the information-theoretic measures from the stimuli in the visual learning task, (2) simulating infant eye-tracking data during the VL task, and (3) estimating the latent parameters at the individual level.](images/poli2024researchpipeline-01.jpg)](https://doi.org/10.1111/desc.13460)

For the proposed project, I have three primary aims:

**(1)** Reproduce the findings using the original data and code.

**(2)** Simulate infant looking behavior in the visual learning task, e.g., looking time in each trial.

**(3)** Fit a hierarchical Bayesian model to estimate latent parameter(s) of interest using the simulated data, e.g., learning performance (saccadic latency x predictability) and/or curiosity (stimulus informativity x looking time).

**(4)** Compare model fit and analyses from simulated data to the original data (Poli et al., 2024).

***Working through the described pipeline will help me develop the analytic toolkit and computational understanding needed for my own research program.***

### Anticipated challenges

Simulating this data and analytic pipeline involves three high-level stages: input generation, hierarchical modeling, and outcome replication, each of which will pose their own computational challenges.

The code to generate the sequences for the visual learning task is publicly available. I will follow Poli et al. (2020 and 2024) to attempt to derive the information-theoretic measures for each trial in the visual learning task. This may be complex and time-consuming to undertake from scratch given the scope of the current project. In the event that this step hinders the completion of the subsequent step, I will reference the original analysis script, found [here](https://data.ru.nl/collections/di/dcc/DSC_2019.00056_127), and/or simulate just a portion of the looking behavior (e.g., looking time) to simplify the process.

### Links

[Project Repository](https://github.com/thenness-y/poli2024)

[Original Paper](https://github.com/thenness-y/poli2024/blob/main/original_paper/Poli2023DevSci.pdf)

[Original Data Repository](https://osf.io/zux9v/overview)

## Methods

### **Reproduction:** 

#### Data Preparation

1.  Load the raw data for the visual learning task.
    -   Combine the two datasets, `Roris_nostd.csv` and `Roris_smiley.csv`.
2.  Convert to model-friendly format.
    -   Create indices and convert to Theano.
3.  Z-score the dependent variables (looking time and saccadic latency)
4.  Z-score the independent variables (information gain, predictability, and surprise)
5.  Handle missing values.

Verify the following columns are present:

-   `subj`: subject ID
-   `nseq`: sequence number
-   `ntrialseq`: trial number within sequence
-   `dwell`: looking time to sequence
-   `slat`: saccadic latency
-   `event`: look-away (binary, either 0 or 1)
-   **`D`: KL divergence or *information gain*** (pre-computed)
-   **`H`: entropy or *predictability*** (pre-computed)
-   `I`: ***surprise*** (pre-computed)

#### Analysis Pipeline

1.  [ ] **Fit the hierarchical Bayesian model (HBM)**

    -   Specify relationships of interest (i.e., between looking behavior and latent parameters).
    -   Fit the model using MCMC sampling:
        -   Sampling details:
            -   500k iterations x 2 chains, toss first 490k
            -   10k kept, 20k total samples per parameter per infant
        -   Initialization = ADVI + mass matrix adaptation
    -   Estimate:
        -   **Processing Speed**: β₀\^SL (intercept for saccadic latency)
        -   **Learning Performance**: β₁\^SL (correlation between saccadic latency and predictability)
        -   **Curiosity**: β₁\^LT (correlation between looking time and information gain)
        -   **Sustained Attention**: λ (from survival function for look-away, controlling for surprise, information gain, and time)

2.  [ ] **Model validation**

    -   Check convergence.

        R\^ threshold should be \< 1.004.

    -   Compare model fit between hierarchical vs. simple (group-only) model

        *Necessary to confirm the model is working correctly. If we don't find that infants look longer at more informative stimuli on average (group infant), model fitting may be wrong. Group-level results should match original findings before proceeding. Must verify that the hierarchical model fits better to prove that individual differences exist.*

        *Authors compared models using WAIC and LOO. Full model (includes individual differences) should have lower scores, indicating a* *better fit. Here's the code chunk where they did this:*

        ``` Python
        model_waic1 = az.loo(idata, var_name="LT_like")
        model_waic2 = az.waic(idata, var_name="LT_like")
        ```

3.  [ ] **Extract individual differences**

    -   Once model has ran, compute median of posterior distributions for each parameter.

        *The HBM produces a probability distribution for each parameter for each infant (e.g., infant X's "learning performance" isn't a single number, but a distribution of plausible values within a CI with 89% confidence). The model represents this as 20,000 samples from the distribution.*

        *The authors computed the median of each infant's distribution t[o get a single value per infant per parameter:]{.underline}*

    ``` Python
    posterior=pd.DataFrame()
    posterior["subjnum"]= markasgood.values.reshape(-1, )
    posterior["LT0"]=np.median(trace["LT0"], axis=0)  # Processing speed (looking time)
    posterior["LT1"]=np.median(trace["LT1"], axis=0)  # Curiosity
    posterior["SL0"]=np.median(trace["SL0"], axis=0)  # Processing speed (saccadic)
    posterior["SL1"]=np.median(trace["SL1"], axis=0)  # Learning performance
    posterior["lambda0"]=np.median(trace["lambda0"], axis=0)  # Sustained attention
    posterior["beta_LA"]=np.median(trace["beta_LA"], axis=0)  # (not used in main analysis)
    posterior.to_csv('posterior_median.csv')
    ```

    -   Save to an output file in which there is one row per infant; columns = latent parameters.

    -   Identify infants with significant individual effects (89% credible intervals excludes zero)

        *In the original paper, the authors identified 57 infants (40%) with a significant coefficient for learning performance; 31 infants (22%) showed significant curiosity effects.*

### Simulation:

\*Indicates steps that may require assistance from the instructional team.

1.  Define the individual sequence and trial structure using `sequences_t.csv`, available [here](https://osf.io/a93qr/files), which contains the target locations.

2.  \*Use the formulas from the supplementary materials to compute the information-theoretic variables for each sequence (or request this code from Poli and colleagues).

3.  \*Generate individual parameters for 106 infants (e.g., baseline looking time, processing speed, etc) .

4.  \*Generate behavioral data for each infant (e.g., looking time, saccadic latency, etc).

5.  Preprocess using same steps as Reproduction.

6.  Test model recovery:

    **Specifically, I aim to recover similar posterior distributions for at least one of the latent parameters (e.g., curiosity) and achieve a comparable model fit with the simulated data.**

### Differences from original study

The computing environments are the same. Visualizations may be carried out in R, but the model and any pre-processing steps will be in Python.

## Project Progress Check 1

### Measure of success

Please describe the outcome measure for the success or failure of your reproduction and how this outcome will be computed.

### Pipeline progress

Earlier in this report, you described the steps necessary to reproduce the key result(s) of this study. Please describe your progress on each of these steps (e.g., data preprocessing, model fitting, model evaluation).

## Results

### Data preparation

Data preparation following the analysis plan.

```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Key analysis

The analyses as specified in the analysis plan.

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).

## Discussion

### Summary of Reproduction Attempt

Open the discussion section with a paragraph summarizing the primary result from the key analysis and assess whether you successfully reproduced it, partially reproduced it, or failed to reproduce it.

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis of the dataset, (b) assessment of the meaning of the successful or unsuccessful reproducibility attempt - e.g., for a failure to reproduce the original findings, are the differences between original and present analyses ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the reproducibility attempt (if you contacted them). None of these need to be long.
